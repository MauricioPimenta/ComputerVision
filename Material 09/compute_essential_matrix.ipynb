{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1076,"status":"ok","timestamp":1699978654811,"user":{"displayName":"Raquel Frizera Vassallo","userId":"02213301178938929097"},"user_tz":180},"id":"v4W2AU0sksMi"},"outputs":[],"source":["import numpy as np\n","import cv2 as cv\n","import scipy.io\n","import sys\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"mzDFe5t5AMa4"},"source":["# Auxiliary functions"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":261,"status":"ok","timestamp":1699978660070,"user":{"displayName":"Raquel Frizera Vassallo","userId":"02213301178938929097"},"user_tz":180},"id":"pDMZRFiNk_Pb"},"outputs":[],"source":["\n","\n","# Return the skew matrix formed from a 3x1 vector\n","def skew(vector):\n","    return np.array([[0, -vector[2], vector[1]],\n","                     [vector[2], 0, -vector[0]],\n","                     [-vector[1], vector[0], 0]])\n","\n","\n","# Estimate Essential Matrix\n","def estimate_essential (ptsl, ptsr):\n","\n","    npoints = ptsl.shape[1] #number of columns\n","\n","    if ptsr.shape[1] != npoints:\n","        raise ValueError(\"Number of points don't match.\")\n","\n","    # Essential Metrix Estimation\n","    # A_nx9.Es_9x1 = 0\n","\n","    A = np.zeros((npoints, 9))\n","\n","    if npoints < 9:\n","        print('Too few mesurements')\n","        sys.exit(0)\n","\n","    # Stack the equation for each pair of matchings\n","    for i in range (npoints):\n","\n","        # A[i] = [ptsl[0,i]*ptsr[0,i], ptsl[0,i]*ptsr[1,i], ptsl[0,i]*ptsr[2,i],\n","        #         ptsl[1,i]*ptsr[0,i], ptsl[1,i]*ptsr[1,i], ptsl[1,i]*ptsr[2,i],\n","        #         ptsl[2,i]*ptsr[0,i], ptsl[2,i]*ptsr[1,i], ptsl[2,i]*ptsr[2,i] ]\n","\n","        A[i,:] = np.kron(ptsl[:,i],ptsr[:,i])\n","\n","    # Check the matrix rank\n","    r = np.linalg.matrix_rank(A)\n","\n","    if r < 8:\n","        print('Measurement matrix rank defficient')\n","        sys.exit(0)\n","\n","\n","    # Compute the SVD of matrix A\n","    U,S,V = np.linalg.svd(A, full_matrices=True)\n","    # Pick the eigenvector corresponding to the smallest eigenvalue\n","    # Define the first estimation for the Essential matrix\n","    E1 = V[-1].reshape(3,3).T\n","\n","    # Compute the SVD of the Essential Matrix\n","    U,S,V = np.linalg.svd(E1,full_matrices=True)\n","    # Substitute the diagonal matrix to project the first estimation into the\n","    # Essential Matrix Space/Domain\n","    S = np.diag([1,1,0])\n","    # Compute the new Essential Matrix belonging to the right domain\n","    E = U.dot(S).dot(V)\n","    # or\n","    #E = np.dot(U,np.dot(S,V))\n","\n","    return E\n","\n","def estimate_normalized_essential (ptsl, ptsr):\n","\n","    ptsl_n, Tl = normalize(ptsl)\n","    ptsr_n, Tr = normalize(ptsr)\n","    # Estimate essential matrix\n","    E = estimate_essential (ptsl_n, ptsr_n)\n","    # reverse normalization\n","    E = np.dot(Tr.T,np.dot(E,Tl))\n","\n","    return E/E[2,2]\n","\n","\n","\n","def calculate_4solutions(E):\n","# Calculate the four possible solutions\n","    #print(\"E: \\n\", E)\n","\n","    # Rotation matrix around the Z-axis of pi/2 radians\n","    W = np.array([[0,-1,0],[1,0,0],[0,0,1]])\n","\n","    # SVD of the Essential Matrix\n","    U,S,Vt = np.linalg.svd(E)\n","\n","    if np.linalg.det(np.dot(U,Vt))<0:\n","        Vt = -Vt\n","    # Compute the four possible solutions\n","    # Two options for rotation:\n","    #    * R = U路W路Vt\n","    #    * R = U路W^T路Vt\n","\n","    # Two option for translation: T and -T\n","    # T = U[:,2] and -T = -U[:,2]\n","\n","    RT = [np.vstack((np.dot(U,np.dot(W,Vt)).T,U[:,2])).T,\n","          np.vstack((np.dot(U,np.dot(W,Vt)).T,-U[:,2])).T,\n","          np.vstack((np.dot(U,np.dot(W.T,Vt)).T,U[:,2])).T,\n","          np.vstack((np.dot(U,np.dot(W.T,Vt)).T,-U[:,2])).T]\n","\n","    print('Print the four solutions:\\n')\n","    print(RT[0] ,'\\n')\n","    print(RT[1] ,'\\n')\n","    print(RT[2] ,'\\n')\n","    print(RT[3] ,'\\n')\n","\n","    return RT\n","\n","\n","# Normalize the points\n","def normalize(pts):\n","\n","    # to be sure that the last line is all of ones - homogeneous coordinates\n","    pts = pts / pts[2]\n","\n","    npoints = pts.shape[1] # number of columns\n","    # Calculate the Centroid\n","    #centx = np.sum (pts[0,:])/npoints\n","    #centy = np.sum (pts[1,:])/npoints\n","    centroid = np.mean(pts[:2],axis=1)\n","    # Calculation of the  mean distance in relation to the centroid\n","    dist_med = sum(np.sqrt((pts[0,:] - centroid[0])**2 + (pts[1,:] - centroid[1])**2))/npoints\n","    # Scale to make the mean distance equal to  sqrt(2)\n","    esc = np.sqrt(2)/dist_med\n","    esc = np.sqrt(2)/np.std(pts[:2])\n","    # Normalization matrix\n","    T = np.array([[esc, 0, -esc*centroid[0]],[0, esc, -esc*centroid[1]],[ 0, 0, 1]])\n","\n","    #Normalized points\n","    pts_norm = np.dot(T,pts)\n","\n","    return pts_norm,T\n","\n","\n","# Drawlines in the images\n","def drawlines(img1,img2,lines,pts1,pts2):\n","    ''' img1 - image on which we draw the epilines for the points in img2\n","        lines - corresponding epilines '''\n","    r,c,ch = img1.shape\n","\n","    img1 = cv.cvtColor(img1,cv.COLOR_RGB2GRAY)\n","    img2 = cv.cvtColor(img2,cv.COLOR_RGB2GRAY)\n","    img1 = cv.cvtColor(img1,cv.COLOR_GRAY2BGR)\n","    img2 = cv.cvtColor(img2,cv.COLOR_GRAY2BGR)\n","\n","    for r,pt1,pt2 in zip(lines,pts1,pts2):\n","        color = tuple(np.random.randint(0,255,3).tolist())\n","        x0,y0 = map(int, [0, -r[2]/r[1] ])\n","        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n","        img1 = cv.line(img1, (x0,y0), (x1,y1), color,1)\n","        img1 = cv.circle(img1,tuple([int(pt1[0]),int(pt1[1])]),5,color,-1)\n","        img2 = cv.circle(img2,tuple([int(pt2[0]),int(pt2[1])]),5,color,-1)\n","    return img1,img2\n","\n","\n","\n","\n","def draw_epipolarlines (img1,img2,pts1,pts2,F):\n","\n","    r,c,ch = img1.shape\n","\n","    img1 = cv.cvtColor(img1,cv.COLOR_RGB2GRAY)\n","    img2 = cv.cvtColor(img2,cv.COLOR_RGB2GRAY)\n","    img1 = cv.cvtColor(img1,cv.COLOR_GRAY2BGR)\n","    img2 = cv.cvtColor(img2,cv.COLOR_GRAY2BGR)\n","\n","    # Find epilines corresponding to points in right image (second image) and\n","    # drawing its lines on left image\n","    lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n","    lines1 = lines1.reshape(-1,3)\n","    img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)\n","    # Find epilines corresponding to points in left image (first image) and\n","    # drawing its lines on right image\n","    lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n","    lines2 = lines2.reshape(-1,3)\n","    img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)\n","    fig=plt.figure(figsize=(18,10))\n","    fig.add_subplot(1,2,1)\n","    plt.imshow(img5)\n","    fig.add_subplot(1,2,2)\n","    plt.imshow(img3)\n","\n","    return\n","\n","\n","\n","def triangulate_point(ptsl,ptsr,Pl,Pr):\n","    \"\"\" Point pair triangulation from\n","    least squares solution. \"\"\"\n","    M = np.zeros((6,6))\n","    M[:3,:4] = Pl\n","    M[3:,:4] = Pr\n","    M[:3,4] = -ptsl\n","    M[3:,5] = -ptsr\n","    U,S,V = np.linalg.svd(M)\n","    X = V[-1,:4]\n","    return X / X[3]\n","\n","def triangulate(ptsl,ptsr,Pl,Pr):\n","    \"\"\" Two-view triangulation of points in\n","    x1,x2 (3*n homog. coordinates). \"\"\"\n","\n","    n = ptsl.shape[1]\n","    if ptsr.shape[1] != n:\n","      raise ValueError(\"Number of points don't match.\")\n","\n","    X = [ triangulate_point(ptsl[:,i],ptsr[:,i],Pl,Pr) for i in range(n)]\n","\n","    return np.array(X).T\n","\n","def select_solution (ptsl,ptsr,Pl,Pr):\n","\n","    # pick the solution with points in front of cameras\n","    ind = 0\n","    maxres = 0\n","    for i in range(4):\n","      # triangulate inliers and compute depth for each camera\n","      X = triangulate(ptsl,ptsr,Pl,Pr[i])\n","      d1 = np.dot(Pl,X)[2]\n","      d2 = np.dot(Pr[i],X)[2]\n","\n","      if (np.sum(d1>0)+np.sum(d2>0)) > maxres:\n","          maxres = np.sum(d1>0)+np.sum(d2>0)\n","          ind = i\n","          infront = (d1>0) & (d2>0)\n","\n","    Tfinal = Pr[ind][:,3]\n","    Rfinal = Pr[ind][:,0:3]\n","\n","    return ind, Tfinal, Rfinal\n","\n","\n","# Check the positive depth constraint\n","def verify_positive_depth(ptsmetric_left,ptsmetric_right,RT):\n","    ##########\n","    # Select the correct solution\n","    ####\n","    # pick the correct solution based on positive depth constraint\n","    # there are two ways (below 2. is used):\n","    # 1. Compute both scales and pick the solution where the majority is\n","    #    positive in both frames\n","    # 2. Compute volume, which has to be positive if the two scales have\n","    #    the same sign and then check whether one of the scale is positive\n","    #    (similar solution suggested by Kanatani, 1993 book).\n","    ######################\n","    lin,col = ptsmetric_left.shape\n","    npoints = col\n","    index = 0\n","    posdepth = np.zeros(4)\n","\n","    for i in range(4):\n","        alpha1 = np.zeros((npoints,1))\n","        alpha2 = np.zeros((npoints,1))\n","\n","        R = RT[i][:,0:3]\n","        t = RT[i][:,3]\n","\n","        for j in range(npoints):\n","            ptsR_hat = skew(ptsmetric_right[:,j])\n","            ptsL = ptsmetric_left[:,j]\n","            ptsR = ptsmetric_right[:,j]\n","            RptsL_hat = skew(R.dot(ptsL))\n","\n","            alpha1[j] = ((-ptsR_hat.dot(t)).T).dot(ptsR_hat.dot(R).dot(ptsL))/(np.linalg.norm(ptsR_hat.dot(t))**2)\n","            alpha2[j] = (RptsL_hat.dot(ptsR)).T.dot(RptsL_hat.dot(t))/(np.linalg.norm(RptsL_hat.dot(ptsR))**2)\n","\n","        depth = np.sum(alpha1>0)\n","        depth2 = np.sum(alpha2>0)\n","        posdepth[i] = depth + depth2\n","\n","\n","    index = np.argmax(posdepth)\n","\n","    Tfinal = RT[index][:,3]\n","    Rfinal = RT[index][:,0:3]\n","    return index,Tfinal,Rfinal\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"atP64HZ0BZEY"},"source":["# Example Cases"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6r6b38VBbCc"},"outputs":[],"source":["def case_one():\n","    # Read images\n","    imgl = cv.imread('img_left.jpg')  #queryimage # left image\n","    imgr = cv.imread('img_right.jpg') #trainimage # right image\n","\n","    # intrinsic parameter matrix\n","\n","    # for the right camera\n","    Kr = np.array([[ 857.1590, 0, 318.2537],[0, 860.8839, 233.3245],[0, 0, 1.0000]])\n","\n","    # for the left camera\n","    Kl = np.array([[855.3492, 0, 319.2672],[0, 859.2368, 247.6019],[0, 0, 1.0000]])\n","\n","\n","    # Extrinsic Parameters\n","    # Translation\n","    Tr = np.array([-118.1274, 0.5238, 0.1311])\n","    Tr = Tr/np.linalg.norm(Tr)\n","    T_hat = skew(Tr)\n","    # Rotation\n","    Rmat = np.array([[ 0.9999,   0.0009,    0.0147],[ -0.0010,    0.9999,    0.0110],[-0.0147,   -0.0110,    0.9998]])\n","\n","\n","    # Read points that were collected manually\n","    data = scipy.io.loadmat('selected_points.mat')\n","\n","    ptsl = data['npt0']\n","    ptsr = data['npt1']\n","\n","    return imgl,imgr,Kl,Kr,ptsl,ptsr,T_hat,Tr,Rmat\n","\n","def case_two():\n","    #Read images\n","    imgl = cv.imread('colorLeft.png')  #queryimage # left image\n","    imgr = cv.imread('colorRight.png') #trainimage # right image\n","\n","    # intrinsic parameter matrix\n","\n","    fm = 403.657593; # Fical distantce in pixels\n","    cx = 161.644318; # Principal point - x-coordinate (pixels)\n","    cy = 124.202080; # Principal point - y-coordinate (pixels)\n","    bl = 119.929; # baseline (mm)\n","    # for the right camera\n","    Kr = np.array([[ fm, 0, cx],[0, fm, cy],[0, 0, 1.0000]])\n","\n","    # for the left camera\n","    Kl = np.array([[fm, 0, cx],[0, fm, cy],[0, 0, 1.0000]])\n","\n","    # Extrinsec parameters\n","    # Translation between cameras\n","    Tr = np.array([-bl, 0, 0])\n","    Tr = Tr/np.linalg.norm(Tr)\n","    T_hat = skew(Tr)\n","    # Rotation\n","    Rmat = np.array([[ 1,0,0],[ 0,1,0],[0,0,1]])\n","\n","\n","\n","    # find the keypoints and descriptors with SIFT\n","    sift = cv.SIFT_create()\n","    kp1, des1 = sift.detectAndCompute(imgl,None)\n","    kp2, des2 = sift.detectAndCompute(imgr,None)\n","\n","    # Solve matching between detected points in both images\n","    # FLANN parameters\n","    FLANN_INDEX_KDTREE = 1\n","    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n","    search_params = dict(checks=50)\n","    flann = cv.FlannBasedMatcher(index_params,search_params)\n","    matches = flann.knnMatch(des1,des2,k=2)\n","    good = []\n","    ptsl = []\n","    ptsr = []\n","\n","    # Select good matches\n","    # ratio test as per Lowe's paper\n","    for i,(m,n) in enumerate(matches):\n","\n","        if m.distance < 0.7*n.distance:\n","            good.append(m)\n","            ptsr.append(kp2[m.trainIdx].pt)\n","            ptsl.append(kp1[m.queryIdx].pt)\n","\n","\n","    ptsl = np.int32(ptsl).T\n","    ptsr = np.int32(ptsr).T\n","\n","    return imgl,imgr,Kl,Kr,ptsl,ptsr,T_hat,Tr,Rmat\n","\n","def case_three():\n","\n","    #Read images\n","    imgl = cv.imread('270_left.jpg')  #queryimage # left image\n","    imgr = cv.imread('270_right.jpg') #trainimage # right image\n","\n","    img_size = imgl.shape\n","    imgl = cv.resize(imgl, (int(img_size[1]/4), int(img_size[0]/4)))\n","\n","    img_size = imgr.shape\n","    imgr = cv.resize(imgr, (int(img_size[1]/4), int(img_size[0]/4)))\n","\n","\n","    Kl = np.array([[ 2.24534083e+03, -1.86235000e-01,  1.00832942e+03],\n","                   [ 0.00000000e+00,  2.24106139e+03,  1.02170932e+03],\n","                   [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n","\n","    Kr = np.array([[2.24011968e+03, 2.23877000e-01, 1.01598269e+03],\n","                   [0.00000000e+00, 2.23629070e+03, 1.03758278e+03],\n","                   [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n","\n","    # Correct intrinsic parameters due to resizing images\n","    Kl = Kl/4\n","    Kl [-1,-1] = 1\n","    Kr = Kr/4\n","    Kr [-1,-1] = 1\n","\n","    Rmat = np.array([[ 0.999995, -0.002636, -0.001449],\n","                     [ 0.002633,  0.999995, -0.001937],\n","                     [ 0.001455,  0.001933,  0.999997]])\n","    Tr = np.array([-4.17709527e+02,-8.92217000e-01,-1.37416000e-01])\n","    Tr = Tr/np.linalg.norm(Tr)\n","    T_hat = skew(Tr)\n","\n","    # find the keypoints and descriptors with SIFT\n","    sift = cv.SIFT_create()\n","    kp1, des1 = sift.detectAndCompute(imgl,None)\n","    kp2, des2 = sift.detectAndCompute(imgr,None)\n","\n","    # Solve matching between detected points in both images\n","    # FLANN parameters\n","    FLANN_INDEX_KDTREE = 1\n","    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n","    search_params = dict(checks=50)\n","    flann = cv.FlannBasedMatcher(index_params,search_params)\n","    matches = flann.knnMatch(des1,des2,k=2)\n","    good = []\n","    ptsl = []\n","    ptsr = []\n","\n","    # Select good matches\n","    # ratio test as per Lowe's paper\n","    for i,(m,n) in enumerate(matches):\n","\n","        if m.distance < 0.7*n.distance:\n","            good.append(m)\n","            ptsr.append(kp2[m.trainIdx].pt)\n","            ptsl.append(kp1[m.queryIdx].pt)\n","\n","\n","    ptsl = np.int32(ptsl).T\n","    ptsr = np.int32(ptsr).T\n","\n","    return imgl,imgr,Kl,Kr,ptsl,ptsr,T_hat,Tr,Rmat\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iGMJTczgAeQ4"},"source":["# Main program with the 3 examples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10WRdTxkq7R3byVeTzLBO8P9NimEiHmTn"},"executionInfo":{"elapsed":12298,"status":"ok","timestamp":1687462617793,"user":{"displayName":"Raquel Frizera Vassallo","userId":"02213301178938929097"},"user_tz":180},"id":"hLJHaU5B4mXP","outputId":"18752a2c-817e-4ed1-a817-3d1a3b694e8a"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["##################### Main ###################\n","\n","\n","CASE = 3\n","\n","if CASE == 1:\n","    imgl0,imgr0,Kl,Kr,ptsl,ptsr,T_hat,Tr,Rmat = case_one()\n","\n","if CASE == 2:\n","    imgl0,imgr0,Kl,Kr,ptsl,ptsr,T_hat,Tr,Rmat = case_two()\n","\n","if CASE == 3:\n","    imgl0,imgr0,Kl,Kr,ptsl,ptsr,T_hat,Tr,Rmat = case_three()\n","\n","\n","\n","\n","\n","# Show images and plot points\n","imgl = cv.cvtColor(imgl0,cv.COLOR_BGR2RGB)\n","imgr = cv.cvtColor(imgr0, cv.COLOR_BGR2RGB)\n","ydim = imgl.shape[0]\n","xdim = imgl.shape[1]\n","\n","\n","plt.figure(figsize=(18,10))\n","plt.subplot(121)\n","plt.imshow(imgl)\n","plt.plot(ptsl[0,:],ptsl[1,:],'b*')\n","plt.subplot(122)\n","plt.imshow(imgr)\n","plt.plot(ptsr[0,:],ptsr[1,:],'m*')\n","\n","\n","# compute image coordinates in metric\n","Kl_inv = np.linalg.inv(Kl)\n","Kr_inv = np.linalg.inv(Kr)\n","\n","lin,col = ptsl.shape\n","npoints = col\n","\n","ptsl_m = np.dot(Kl_inv,np.vstack((ptsl,np.ones((1,npoints)))))\n","ptsr_m = np.dot(Kr_inv,np.vstack((ptsr,np.ones((1,npoints)))))\n","\n","\n","#Estimate the Essential matrix using our method\n","print('\\n##############################################')\n","print('Essential Matrix estimation using our method')\n","print('##############################################\\n')\n","\n","E = estimate_normalized_essential(ptsl_m, ptsr_m)\n","\n","print('Essential Matrix')\n","print(E,'\\n')\n","\n","# Calculate the four possible solutions\n","RT = calculate_4solutions(E)\n","\n","# Select the right solution using the positive depth constraint\n","index,Tfinal,Rfinal = verify_positive_depth(ptsl_m,ptsr_m,RT)\n","\n","P1 = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]])\n","ind_test,T_test,R_test = select_solution (ptsl_m,ptsr_m,P1,RT)\n","\n","print('Final solution using our method has the index: ', index)\n","print(Tfinal)\n","print(Rfinal,'\\n')\n","\n","print('Another solution using triangulation: ', ind_test)\n","print(T_test)\n","print(R_test)\n","\n","# Draw epipolar lines\n","pts1 = ptsl[0:2,:].T\n","pts2 = ptsr[0:2,:].T\n","# Compute the Fundamental Matrix\n","F = (np.linalg.inv(Kr.T)).dot(E).dot(Kl_inv)   # F = (Kr^-T).E.(Kl^-1)\n","\n","draw_epipolarlines (imgl,imgr,pts1,pts2,F)\n","\n","\n","print('\\n##############################################')\n","print('Essential Matrix estimation using OpenCV')\n","print('##############################################\\n')\n","\n","# Estimate the Fundamental matrix\n","# cv.FM_8POINT + cv.FM_RANSAC\n","pts1 = ptsl[0:2,:].T\n","pts2 = ptsr[0:2,:].T\n","\n","# Estimate the Fundamental matrix\n","# cv.FM_8POINT + cv.FM_RANSAC\n","F, mask = cv.findFundamentalMat(pts1,pts2,cv.RANSAC,1,0.9999999)\n","# We select only inlier points\n","pts1 = pts1[mask.ravel()==1]\n","pts2 = pts2[mask.ravel()==1]\n","\n","# Compute the Essential Matrix\n","EopenCV = (Kr.T).dot(F).dot(Kl)\n","EopenCV = EopenCV /EopenCV [2,2]\n","print('Essential Matrix - OpenCV')\n","print(EopenCV,'\\n')\n","\n","# Calculate the four possible solutions\n","RT = calculate_4solutions(EopenCV)\n","\n","# Select the right solution using the positive depth constraint\n","index,Tfinal,Rfinal = verify_positive_depth(ptsl_m,ptsr_m,RT)\n","P1 = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]])\n","ind_test,T_test,R_test = select_solution (ptsl_m,ptsr_m,P1,RT)\n","\n","print('Final solution using our method has the index: ', index)\n","print(Tfinal)\n","print(Rfinal,'\\n')\n","\n","print('Another solution using triangulation: ', ind_test)\n","print(T_test)\n","print(R_test)\n","\n","# Draw epipolar lines\n","pts1 = ptsl[0:2,:].T\n","pts2 = ptsr[0:2,:].T\n","# Compute the Fundamental Matrix\n","F = (np.linalg.inv(Kr.T)).dot(EopenCV).dot(Kl_inv)\n","\n","draw_epipolarlines (imgl,imgr,pts1,pts2,F)\n","\n","\n","# Compute the real Essential Matrix\n","Ereal = T_hat.dot(Rmat)\n","print('\\n##############################################')\n","print('Real Solution')\n","print('##############################################\\n')\n","print('E:\\n',Ereal,'\\n')\n","print('R:\\n',Rmat,'\\nT:\\n',Tr)\n","\n","pts1 = ptsl[0:2,:].T\n","pts2 = ptsr[0:2,:].T\n","\n","# Compute the Fundamental Matrix\n","F = (np.linalg.inv(Kr.T)).dot(Ereal).dot(Kl_inv)\n","\n","draw_epipolarlines (imgl,imgr,pts1,pts2,F)\n","\n","\n","plt.show()\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}